{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b841615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'search': 'give a ruskin bond bithday', 'documents': [Document(id='f355f9af-d2e8-4741-9c53-c95284b2a433', metadata={}, page_content='A container is a lightweight, standalone, and executable unit that includes:'), Document(id='ee23aeed-4d0a-43c0-9909-3a42684c2690', metadata={}, page_content='A hypervisor ecosystem refers to the complete set of tools, technologies, and services that work with a hypervisor to manage, secure, and optimize virtualized environments.'), Document(id='87300848-5127-4473-93c4-21ad510b0846', metadata={}, page_content='A Docker Image is a read-only template used to create containers.'), Document(id='339b29d3-3c62-45af-b9a7-8e97f7732f2b', metadata={}, page_content='Containers share the host OS kernel, which makes them faster and more resource efficient compared to Virtual Machine.')], 'keywords': ['docker', 'container', 'image'], 'answer': \"I think there may be some confusion here!\\n\\nThe context you provided talks about containers, hypervisors, and Docker Images. But then you ask me to give a Ruskin Bond birthday?\\n\\nRuskin Bond is an Indian author, poet, and essayist, known for his children's books and short stories. He was born on May 18, 1934.\\n\\nSo, the answer to your question is: May 18, 1934!\"}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, List\n",
    "from langchain.schema import Document\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.retrievers import ArxivRetriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "\n",
    "# Load API key\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize LLM and embeddings\n",
    "llm = Ollama(model=\"llama3\", temperature=0)\n",
    "embeddings = HuggingFaceEmbeddings(model\"all-MiniLM-L6-v2\"_name=)\n",
    "\n",
    "# Corrected retriever initialization\n",
    "retriever = ArxivRetriever(\n",
    "    load_max_docs=2,\n",
    "    get_full_documents=True,\n",
    ")\n",
    "\n",
    "# Define the state structure\n",
    "class AgentState(TypedDict):\n",
    "    search: str\n",
    "    documents: List[Document]\n",
    "    keywords: List[str]\n",
    "    answer: str\n",
    "\n",
    "# Example documents\n",
    "sample_texts = [\n",
    "    \"A container is a lightweight, standalone, and executable unit that includes:\",\n",
    "    \"Containers share the host OS kernel, which makes them faster and more resource efficient compared to Virtual Machine.\",\n",
    "    \"A Docker Image is a read-only template used to create containers.\",\n",
    "    \"A hypervisor ecosystem refers to the complete set of tools, technologies, and services that work with a hypervisor to manage, secure, and optimize virtualized environments.\"\n",
    "]\n",
    "\n",
    "documents = [Document(page_content=text) for text in sample_texts]\n",
    "\n",
    "# Build FAISS vectorstore\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "retriever = vectorstore.as_retriever(k=3)\n",
    "\n",
    "# Node 1\n",
    "def need_line(state: AgentState):\n",
    "    search = state.get(\"search\", \"\")\n",
    "    keywords = state.get(\"keywords\", [])\n",
    "    if not keywords:\n",
    "        return {**state, \"answer\": \"\", \"search\": search}\n",
    "    answer_found = any(keyword.lower() in search.lower() for keyword in keywords)\n",
    "    return {**state, \"answer\": str(answer_found)}\n",
    "\n",
    "# Node 2\n",
    "def check_search(state: AgentState):\n",
    "    search = state.get(\"search\", \"\")\n",
    "    documents = retriever.invoke(search)\n",
    "    return {**state, \"documents\": documents}\n",
    "\n",
    "# Node 3\n",
    "def answer_doc(state: AgentState):\n",
    "    search = state.get(\"search\", \"\")\n",
    "    documents = state.get(\"documents\", [])\n",
    "    if documents:\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "        prompt = f\"Based on the context below, answer the question.\\nContext:\\n{context}\\nQuestion: {search}\\nAnswer:\"\n",
    "    else:\n",
    "        prompt = f\"Answer the question based on your knowledge: {search}\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    return {**state, \"answer\": response}\n",
    "\n",
    "# Conditional branching\n",
    "def found_search(state: AgentState):\n",
    "    if state.get(\"answer\") == \"True\":\n",
    "        return \"answer_doc\"\n",
    "    else:\n",
    "        return \"search\"\n",
    "\n",
    "# Workflow\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"need_line\", need_line)\n",
    "graph.add_node(\"check_search\", check_search)\n",
    "graph.add_node(\"answer_doc\", answer_doc)\n",
    "\n",
    "graph.add_edge(START, \"need_line\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"need_line\",\n",
    "    found_search,\n",
    "    {\n",
    "        \"answer_doc\": \"answer_doc\",\n",
    "        \"search\": \"check_search\",\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.add_edge(\"check_search\", \"answer_doc\")\n",
    "graph.add_edge(\"answer_doc\", END)\n",
    "\n",
    "chain = graph.compile()\n",
    "\n",
    "# Function to ask questions\n",
    "def ask_question(question: str):\n",
    "    initial_state = {\n",
    "        \"search\": question,\n",
    "        \"documents\": [],\n",
    "        \"answer\": \"\",\n",
    "        \"keywords\": [\"docker\", \"container\", \"image\"],\n",
    "    }\n",
    "    return chain.invoke(initial_state)\n",
    "\n",
    "# Run test\n",
    "question1 = \"give a ruskin bond bithday\"\n",
    "result1 = ask_question(question1)\n",
    "print(result1)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
